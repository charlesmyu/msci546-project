{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Census Data\n",
    "The goal of this file is to parse data from census tables into an intermediate format so we can merge them into a master table later. \n",
    "\n",
    "## Steps:\n",
    "1. Duplicate the folder (i.e. `S2301`) within `census-data`, and rename the folder to the name of the Census table you are processing\n",
    "2. Empty the `raw` folder\n",
    "3. Download census data and place into `raw`. Each year of data should be in its own csv file. Rename each file into `<year>.csv`\n",
    "4. Update the transformation in the code block below to obtain the desired columns, and rename them if necessary\n",
    "    - For most tables, you will only need to lookup the column code of the feature you are looking to obtain, and match that to a readable name in `features`\n",
    "5. Verify the transformation is correct using the `df.head()` statement already placed there for you. If it looks good, the data is good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cfips  pct_born_us_citizen  pct_naturalized_us_citizen  pct_not_us_citizen\n",
      "1  01001            97.886838                    1.115633            0.997529\n",
      "2  01003            96.751574                    1.559304            1.689123\n",
      "3  01005            97.339796                    1.003778            1.656425\n",
      "4  01007            98.976971                    0.181577            0.841453\n",
      "5  01009            95.454940                    1.576291            2.968769\n",
      "   cfips  pct_born_us_citizen  pct_naturalized_us_citizen  pct_not_us_citizen\n",
      "1  01001            97.981884                    1.048913            0.969203\n",
      "2  01003            96.554657                    1.594853            1.850490\n",
      "3  01005            97.494376                    1.086029            1.419595\n",
      "4  01007            98.557287                    0.572646            0.870067\n",
      "5  01009            95.640559                    1.519646            2.839795\n",
      "   cfips  pct_born_us_citizen  pct_naturalized_us_citizen  pct_not_us_citizen\n",
      "1  01001            97.654388                    1.354280            0.991333\n",
      "2  01003            96.276841                    1.714984            2.008176\n",
      "3  01005            97.283230                    1.320926            1.395844\n",
      "4  01007            98.488419                    0.622416            0.889166\n",
      "5  01009            95.459510                    1.674728            2.865762\n",
      "   cfips  pct_born_us_citizen  pct_naturalized_us_citizen  pct_not_us_citizen\n",
      "1  01001            97.658118                    1.148475            1.193408\n",
      "2  01003            96.578389                    1.690878            1.730733\n",
      "3  01005            97.446655                    0.994965            1.558379\n",
      "4  01007            98.417806                    0.657013            0.925181\n",
      "5  01009            95.647130                    1.864774            2.488096\n"
     ]
    }
   ],
   "source": [
    "def process_file(filename: str):\n",
    "    year = filename[:filename.find(\".\")]\n",
    "    df = pd.read_csv('./raw/' + filename)\n",
    "    df['cfips'] = df['GEO_ID'].apply(lambda x: x[-5:])\n",
    "\n",
    "    # Map column codes to human-readable names. \n",
    "    # ==============\n",
    "    features = {\n",
    "        'B05001_001E': 'total_population', \n",
    "        'B05001_002E': 'us_born', \n",
    "        'B05001_003E': 'us_pr_born', \n",
    "        'B05001_004E': 'us_abroad_born',\n",
    "        'B05001_005E': 'us_naturalized',\n",
    "        'B05001_006E': 'us_not_citizen'\n",
    "    }\n",
    "\n",
    "    df = df.iloc[1:]\n",
    "    df = df.filter(items=['cfips'] + list(features.keys()))\n",
    "    df = df.rename(columns=features)\n",
    "    df = df.dropna()\n",
    "    for feature in features.values():\n",
    "        df[feature] = df[feature].apply(lambda x: 0 if x == 'null' else int(x))\n",
    "    df['pct_born_us_citizen'] = 100*(df['us_born'] + df['us_pr_born'] + df['us_abroad_born'])/df['total_population']\n",
    "    df['pct_naturalized_us_citizen'] = 100*df['us_naturalized']/df['total_population']\n",
    "    df['pct_not_us_citizen'] = 100*df['us_not_citizen']/df['total_population']\n",
    "    df = df.filter(items=['cfips', 'pct_born_us_citizen', 'pct_naturalized_us_citizen', 'pct_not_us_citizen'])\n",
    "    # ==============\n",
    "\n",
    "    print(df.head())\n",
    "    df.to_csv('./parsed/' + year + '.csv', index=False)\n",
    "\n",
    "for filename in os.listdir(\"./raw\"):\n",
    "    process_file(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
